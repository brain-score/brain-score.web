{% extends 'benchmarks/base.html' %}
{% load static %}

{# site navigation #}
{% block navbar %}
    <nav class="navbar is-fixed-top is-transparent" role="navigation"
         content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
        <div class="container">
            <div class="navbar-brand">
                <a href="{{ url }}/competition" class="navbar-item">
                    <img src="/static/benchmarks/img/logo-competition.png"/>
                </a>

                <a role="button" class="navbar-burger" data-target="navMenu" aria-label="menu" aria-expanded="false">
                    <span aria-hidden="true"></span>
                    <span aria-hidden="true"></span>
                    <span aria-hidden="true"></span>
                </a>
            </div>
            <div id="navMenu" class="navbar-menu">
                <div class="navbar-end">
                    <a class="navbar-item" href="#prizes">Prizes</a>
                    <a class="navbar-item" href="#benchmarks">Benchmarks</a>
                    <a class="navbar-item" href="#workshop">Cosyne Workshop</a>
                    <a class="navbar-item" href="#leaderboard">Leaderboard</a>
                    <a class="navbar-item" href="#brain-score">Brain-Score</a>
                    <a class="navbar-item" href="#tutorial">Tutorial</a>
                    <a class="navbar-item" href="#contact">Contact</a>
                    <a class="navbar-item" href="#FAQ">FAQ</a>
                </div>
            </div>
        </div>
    </nav>
{% endblock %}

{% block content %}
    <section class="hero competition-hero">
        <div class="hero-body container">
            <p class="title">
                2022 Brain-Score Competition
            </p>
        </div>
    </section>

    <section id="overview" class="section container center">
        {# overview #}
        <p>
            Brain-Score is hosting a competition for the most brain-like ventral stream model,
            with a prize pool of <span id="prize-pool">$6,000</span>.
            Model submissions will automatically be tested on benchmarks ranging from V1 to IT to behavior,
            and <a href="#prizes">prizes will be awarded in three categories</a>.
        <p>

        <p>
            Submissions are open now until February 15, 2022.
            Check out the flyer below for more information.
            If you have any questions, please consult the FAQ section
            and feel free to reach out to the Brain-Score team.
            Good luck!
        </p>
        <embed width="191" height="207" src="{% static "/benchmarks/img/competition_logos/flyer.PNG" %}">
    </section>

    {# prizes #}
    <section id="prizes" class="section container">
        <h2 class="title is-2">Prizes</h2>
        <div class="card-content">
            Prize Category 1: <span class="prize-category">Overall Brain-Score (V1, V2, V4, IT, Behavior)</span>
            <ol class="prizes">
                <li>First Prize: <span class='information'>$2,000</span></li>
                <li>Second Prize: <span class='information'>$1,500</span></li>
                <li>Third Prize: <span class='information'>$500</span></li>
            </ol>
        </div>
        <div class="card-content">
            Prize Category 2: <span class="prize-category">V1</span>
            <ol class="prizes">
                <li>First Prize: <span class='information'>$1,000</span></li>
            </ol>
        </div>
        <div class="card-content">
            Prize Category 3: <span class="prize-category">Behavior</span>
            <ol class="prizes">
                <li>First Prize: <span class='information'>$1,000</span></li>
            </ol>
        </div>

        See the
        <a target="_blank" href="{% static "benchmarks/official-rules.pdf" %}">official rules</a>
        for full details.
    </section>

    {# stimuli #}
    <section id="benchmarks" class="section container">
        <h2 class="title is-2">Benchmarks</h2>
        <div id="stimuli-samples" class="samples_container container">
            {% for stimulus_sample in stimuli_samples %}
                <img class="stimulus_sample"
                     src="/static/benchmarks/img/benchmark_samples/{{ stimulus_sample.path }}"
                     title="from benchmark {{ stimulus_sample.benchmark_short_name }}"
                     alt="sample {{ stimulus_sample.path }}"/>
            {% endfor %}
        </div>
    </section>

    {# workshop #}
    <section id="workshop" class="section container">
        <h2 class="title is-2">Cosyne Workshop</h2>
        We will announce the competition winners at a <a href="https://www.cosyne.org/">COSYNE 2022</a> workshop!
        We encourage submitters to attend the workshop, but this is not a requirement for participation.
    </section>

    {# leaderboard #}
    <section id="leaderboard" class="section container tablecenter is-centered">
        <h2 class="title is-2">Competition Leaderboard</h2>
        <div class="tabs is-centered is-boxed">
            <ul>
                {% for leaderboard_key in leaderboard_keys %}
                    <li data-target="tab-{{ leaderboard_key }}"
                        class="tab leaderboard-track {% if leaderboard_key == 'average' %}is-active{% endif %}">
                        <a>
                            <span>{{ leaderboard_key }}</span>
                        </a>
                    </li>
                {% endfor %}
            </ul>
        </div>
        {# ideally this would be a for loop, but I don't know how to look up {benchmarks_average, benchmarks_V1} based on a variable #}
        <div id="tab-average"
             class="tab-content">
            {% include "benchmarks/table.html" with benchmarks=benchmarks_average models=models_average %}
        </div>
        <div id="tab-V1"
             class="tab-content" style="display: none">
            {% include "benchmarks/table.html" with benchmarks=benchmarks_V1 models=models_V1 %}
        </div>
        <div id="tab-behavior"
             class="tab-content" style="display: none">
            {% include "benchmarks/table.html" with benchmarks=benchmarks_behavior models=models_behavior %}
        </div>
    </section>

    {# brain-score #}
    <section id="brain-score" class="section container">
        <h2 class="title is-2">Brain-Score</h2>
    </section>

    {# tutorial #}
    <section id="tutorial" class="section container">
        <h2 class="title is-2">Tutorial</h2>

        <br> To enter the competition,
        simply create an account on our main website
        <a href="https://www.brain-score.org">here</a> and submit a model.
        A full length <a href="https://brain-score.readthedocs.io/en/latest/modules/model_tutorial.html">tutorial</a> <br>
        is also available that covers the model submission process, as well as
        a quickstart guide for those that want to get up and running as soon as possible. <br><br>

        To facilitate model submission, we provide helper wrappers for neural networks implemented in Pytorch,
        Tensorflow or Keras.<br> Submitted models can be standard artificial neural networks (ANNs)
        for computer vision - <span class='contact-link'>base models</span> - or actual
        <span class='bold-emphasis'>brain models</span> <br> with their internal
        components <span class='italic-emphasis'>committed to specific visual areas</span>, and their field-of-view mapped to a
        spatial visual <br> extent (in visual degrees).  The difference between base and brain model are also shown in
        the diagram below, and for more information <br> about model details, please visit our tutorial mentioned above.

        <br> <br>
        <figure>
              <img src="{% static "/benchmarks/img/diagram.png" %}"
                   alt="Base v. Brain Models" height="1250" width="750">
              <figcaption>Figure from
                  <a href="https://www.cell.com/neuron/pdf/S0896-6273(20)30605-X.pdf">Schrimpf et al. 2020</a>  </figcaption>
        </figure>


        <br> <br>
        Happy submitting!


    </section>

    {# contact #}
    <section id="contact" class="section container">
        <h2 class="title is-2">Contact</h2>
         <h4> If you have any questions, feel free to email one of the team members below!</h4>
    <ul>
        <li>Martin Schrimpf - msch@mit.edu</li>
        <li>Tiago Marques - tmarques@mit.edu</li>
        <li>Mike Ferguson - mferg@mit.edu</li>
    </ul>

    You can also enter our competition <span class='bold-emphasis'>Slack Channel</span> with this
    <a href="https://join.slack.com/t/brainscorecom-otr4776/shared_invite/zt-102tbg73n-DD1qQ7DpHfXV8l~vH1N~WQ">
        link</a>. We will be posting competition <br>updates, model support, and other assistance in this channel,
            so feel free to join!
    </section>

    {# FAQ #}
    <section id="FAQ" class="section container center">
        <h2 class="title is-2">FAQ</h2>
        <ol>
            <li>
                <h4>How do I submit a model?</h4>
                <p> We have a full length <a
                        href="https://brain-score.readthedocs.io/en/latest/modules/model_tutorial.html">
                    tutorial</a> that walks users through the submission process- feel free to
                    take a look, as it covers model submission, scoring, and results.
                </p>
            </li>
            <li>
                <h4>Why did you choose these benchmarks to score models against?</h4>
                <p>
                    We currently use the PLS25 neural predictivity metric to rank models; this is an established
                    metric,
                    but since itâ€™s most likely far from perfect, we will iterate on this going forward.
                    We are also including novel, unpublished, recordings (Sanghavi2020, SanghaviJozwik2020,
                    SanghaviMurty2020)-
                    these data are from a single monkey, and while we verified data quality and signal reliability,
                    the benchmarks are not vetted as strongly as the other datasets. We will discuss implications
                    and empirical results of these benchmarks at the Cosyne workshop.
                    Based on this yearâ€™s results, we will also discuss if we should only include benchmarks from
                    recordings with n>=2 monkeys. Please join the workshop and join the slack
                    channel if you have input on these questions!
                </p>
            </li>
            <li>
                <h4>I have data that could be useful -- can I submit a benchmark?</h4>
                <p>
                    We also have a tutorial for those who wish to submit benchmarks, found
                    <a href="https://brain-score.readthedocs.io/en/latest/modules/benchmark_tutorial.html">
                        here</a>. We strongly encourage those with useful data to submit a poster at the
                    <a href="https://www.cosyne.org/">COSYNE 2022</a> workshop as well.
                </p>
            </li>
            <li>
                <h4>Who will get prizes?</h4>
                <p>
                    See the above section on the prize breakdown.
                </p>
            </li>
            <li>
                <h4>Does my model have to beat the current most brain-like model on brain-score.org?</h4>
                <p>
                    Nope! You only have to be the best out of all the competition submissions.
                </p>
            </li>
            <li>
                <h4>Is public data available?</h4>
                <p>
                    Yes. Public data splits of many of the benchmarks can be found
                    <a href="https://github.com/brain-score/brain-score/blob/master/brainscore/benchmarks/public_benchmarks.py#L87">here</a>.
                    Use the list_public_assemblies function
                    <a href="https://github.com/brain-score/brain-score/blob/master/brainscore/benchmarks/public_benchmarks.py#L87">
                        here</a> as well to view all available public data.
                </p>
            </li>
        </ol>
    </section>

    {# sponsors #}
    <section class="section container">
    <h2 class="title is-2">Sponsors</h2><br>
        <div class="columns">
            <div class="column">

                <a href="https://quest.mit.edu/">
                    <figure >
                        <img src="{% static "/benchmarks/img/competition_logos/quest.PNG" %}" alt="MIT Quest"
                             height="300" width="300">
                    </figure>
                </a>
            </div>

            <div class="column">
                <a href="https://engineering.purdue.edu/C-BRIC">
                    <figure>
                        <img src="{% static "/benchmarks/img/competition_logos/cbric.png" %}" alt="C-BRIC"
                        height="300" width="300">
                    </figure>
                </a>
            </div>

            <div class="column">
                <a href="https://mitibmwatsonailab.mit.edu/">
                    <figure>
                       <img src="{% static "/benchmarks/img/competition_logos/ibm.jpg" %}" alt="MIT-IBM Watson AI Lab"
                       height="300" width="300">
                    </figure>
                </a>
            </div>
        </div>
    </section>
{% endblock %}